{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "r2xG3HQiTN6I",
        "W0dbJPbZgbaq",
        "tBap24QdgqGd",
        "V8Q57_87r4Ac",
        "tMZ_3AVtsOV9",
        "0hQ0kDLOsirI",
        "pY4VkmvrteiY",
        "8_GqUg0wsx56",
        "Q8RNysbVtHM7"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nathasha-naranpanawa/COMP4702_2024/blob/main/Wk8_pytorch_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(torch.__version__)\n",
        "print('Cuda Available : {}'.format(torch.cuda.is_available()))\n",
        "if torch.cuda.is_available():\n",
        "  print('GPU - {0}'.format(torch.cuda.get_device_name()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uoq3kMPf9Cn",
        "outputId": "10a4b5bf-ac16-4ee3-d0d3-a74655c74d1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "2.2.1+cu121\n",
            "Cuda Available : True\n",
            "GPU - Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN"
      ],
      "metadata": {
        "id": "r2xG3HQiTN6I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNNs are neural networks that are structured in a certain way to take advantage of the inherent structure in images. They are just as easy to make in PyTorch as MLPs! :o"
      ],
      "metadata": {
        "id": "bw55y386YGvX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tasks for you\n",
        "\n",
        "Now you've seen how easy it is to create an MLP/CNN in PyTorch to experiment with the parameters.\n",
        "\n",
        "**Question 1:**\n",
        "Modify the CNN class by adding 2 CNN layers following a softmax classifier in `def __init__()` and `def forward()`. The basic structure of a CNN layer is:\n",
        "*   Convolutional Layer (with/without padding or stride)\n",
        "*   ReLU activation function\n",
        "*   Pooling operation (*e.g.*, max pooling)\n",
        "\n",
        "**Question 2:**\n",
        "*   Implement training and testing procedure of CNN model on MNIST dataset.\n",
        "\n",
        "**Question 3:**\n",
        "*   Try different optimisers and compare the performance.\n",
        "\n",
        "**Question 4:**\n",
        "*   Modify the CNN class again by adding more advanced layers (e.g., Dropout).\n",
        "\n",
        "To do the questions above more systematically, it might be useful to design some kind of experiment where you sweep some/all/more than the parameters mentioned above.\n",
        "\n",
        "**Question 5:**\n",
        "*   Try a different color image (*e.g.* CIFAR10). This is a dataset of colour images, so you will need a CNN with RGB channels. There are many example on the web that show how to do this.\n",
        "\n",
        "\n",
        "Note: CNNs take some time to train so have a think about how many parameters are in a CNN and the best way you can reduce them.\n",
        "\n",
        "---\n",
        "\n",
        "### Some resources which might be useful:\n",
        "*   [Convolutional Layers](https://pytorch.org/docs/stable/nn.html#convolution-layers)\n",
        "*   [Pooling Layers](https://pytorch.org/docs/stable/nn.html#pooling-layers)\n",
        "*   [Padding Layers](https://pytorch.org/docs/stable/nn.html#padding-layers)\n",
        "*   [Optimizers](https://pytorch.org/docs/stable/optim.html#module-torch.optim)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "j7puImtsYRBP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LOAD & PRE-PROCESSING DATASET\n",
        "\n"
      ],
      "metadata": {
        "id": "W0dbJPbZgbaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert PIL Image to tensor\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize the pixel values\n",
        "])\n",
        "\n",
        "# Load MNIST training dataset with transformations\n",
        "mnist_train = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "mnist_test = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Split dataset into training, validation, and test sets\n",
        "train_size = int(0.8 * len(mnist_train))\n",
        "val_size = len(mnist_train) - train_size\n",
        "mnist_train, mnist_val = random_split(mnist_train, [train_size, val_size])\n",
        "\n",
        "# Define data loaders\n",
        "train_loader = DataLoader(mnist_train, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(mnist_val, batch_size=128)\n",
        "test_loader = DataLoader(mnist_test, batch_size=128)"
      ],
      "metadata": {
        "id": "f1Ey-NqLTOBc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ca74f0d-7103-4229-d0ca-234533918df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 111694506.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 73371104.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 30972687.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 12811384.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN"
      ],
      "metadata": {
        "id": "tBap24QdgqGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convolutional neural network (two convolutional layers)\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # TODO: Two 2 CNN layers with 1 output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        #TODO: Implement the forward function\n",
        "        return out"
      ],
      "metadata": {
        "id": "Aj7p2QmcgrO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters\n",
        "\n",
        "# Model Intitialization\n",
        "\n",
        "# Loss and optimizer\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # Extracting mini-bacth\n",
        "    for i, (images, labels) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}\")):\n",
        "\n",
        "        # Put data and model on the same device\n",
        "\n",
        "        # Forward pass\n",
        "\n",
        "        # Backward and optimize\n",
        "\n",
        "    # Validate the model\n",
        "    # TODO: Validating CNN model\n",
        "\n",
        "    val_accuracy = correct * 100 / total\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Validation Accuracy: {val_accuracy:.2f}%')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQRtzpHGizaJ",
        "outputId": "2b29622e-be48-4e55-ff20-d2ff8bef6106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 375/375 [00:11<00:00, 33.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Validation Accuracy: 17.43%\n",
            "Accuracy of the network on the 10000 test images: 17.425 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 375/375 [00:11<00:00, 33.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/5], Validation Accuracy: 25.77%\n",
            "Accuracy of the network on the 10000 test images: 25.775 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 375/375 [00:11<00:00, 33.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/5], Validation Accuracy: 34.37%\n",
            "Accuracy of the network on the 10000 test images: 34.36666666666667 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 375/375 [00:12<00:00, 31.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/5], Validation Accuracy: 43.58%\n",
            "Accuracy of the network on the 10000 test images: 43.583333333333336 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 375/375 [00:11<00:00, 31.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/5], Validation Accuracy: 52.42%\n",
            "Accuracy of the network on the 10000 test images: 52.416666666666664 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Test the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvUTykeYlVbK",
        "outputId": "570097b4-7cd7-4bce-819f-bf214f93b2ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 52.85 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN ON CIFAR-10"
      ],
      "metadata": {
        "id": "V8Q57_87r4Ac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and pre-process CIFAR-10"
      ],
      "metadata": {
        "id": "P-hEoNJOr8tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations for the dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert PIL Image to tensor\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize the pixel values to range [-1, 1]\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "train_dataset_cifar = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset_cifar = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "# TODO: Split dataset into training, validation, and test sets\n",
        "\n",
        "# TODO: Define data loaders"
      ],
      "metadata": {
        "id": "rz_Sn24mr7-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### VISUALIZATION"
      ],
      "metadata": {
        "id": "tMZ_3AVtsOV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the classes in CIFAR-10\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Function to show images\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # Unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# Get some random training images\n",
        "dataiter = iter(train_loader_cifar)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# Print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "metadata": {
        "id": "WNUQhsAFsNky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN MODEL FOR CIFAR-10"
      ],
      "metadata": {
        "id": "0hQ0kDLOsirI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### DEFINE MODEL"
      ],
      "metadata": {
        "id": "pY4VkmvrteiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convolutional neural network (two convolutional layers)\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # TODO: Define some CNN layers\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Implement forward()\n",
        "        return x"
      ],
      "metadata": {
        "id": "tMMFlHU4siwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TRAINING"
      ],
      "metadata": {
        "id": "8_GqUg0wsx56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# TODO: Hyperparameters\n",
        "\n",
        "# TODO: Model Initialization\n",
        "\n",
        "# TODO: Loss and optimizer\n",
        "\n",
        "# TODO: Train the model\n",
        "# Loop over epochs\n",
        "        # Forward pass\n",
        "\n",
        "        # Backward and optimize\n",
        "\n",
        "    # Validate the model\n",
        "\n",
        "    val_accuracy = correct * 100 / total\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Validation Accuracy: {val_accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "JUBZOIHEsx--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TESTING"
      ],
      "metadata": {
        "id": "Q8RNysbVtHM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model"
      ],
      "metadata": {
        "id": "z6nGDwVqtHWn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}